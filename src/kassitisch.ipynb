{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4888448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "db_file = \"kassite_names_db.json\"\n",
    "\n",
    "if os.path.exists(db_file):\n",
    "    with open(db_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        db = json.load(file)\n",
    "    print(f\"Database loaded! {len(db)} entries found.\")\n",
    "else:\n",
    "    db = []\n",
    "    print(\"New database initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39337e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kassitische_datenbank = []\n",
    "wort_1 = {\n",
    "    \"transcription\": \"mali\", \n",
    "    \"meaning\": \"human\", \n",
    "    \"word type\": \"Noun\", \n",
    "    \"liability\": \"sure\"\n",
    "}\n",
    "\n",
    "wort_2 = { \"transcription\": \"alzibadar\", \"meaning\": \"colour term\", \"word type\": \"adjective\"} \n",
    "\n",
    "wort_3 = { \"transcription\": \"bur\", \"meaning\": \"strong\", \"word type\": \"adjective\"}\n",
    "\n",
    "kassitische_datenbank.append(wort_1)\n",
    "kassitische_datenbank.append(wort_2)\n",
    "kassitische_datenbank.append(wort_3)\n",
    "\n",
    "print(f\"Anzahl der Wörter in der Datenbank: {len(db)}\")\n",
    "print(kassitische_datenbank)\n",
    "\n",
    "import json\n",
    "with open(\"kassite_names_db.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(kassitische_datenbank, file, indent=4)\n",
    "print(\"Saved to file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c67735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "db_file = \"kassite_names_db.json\"\n",
    "if os.path.exists(db_file):\n",
    "    try:\n",
    "        with open(db_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            db = json.load(file)\n",
    "        print(f\"Datenbank geladen: {len(db)} Eintraege gefunden.\")\n",
    "    except json.JSONDecodeError:\n",
    "        db = []\n",
    "        print(\"Datei war leer oder fehlerhaft, starte neue Datenbank.\")\n",
    "else:\n",
    "    db = []\n",
    "    print(\"Neue Datenbank initialisiert.\")\n",
    "\n",
    "\n",
    "excel_file = None\n",
    "for f in os.listdir():\n",
    "    if f.startswith(\"Kassitische\") and f.endswith(\".xlsx\") and not f.startswith(\"~$\"):\n",
    "        excel_file = f\n",
    "        break\n",
    "\n",
    "\n",
    "if excel_file:\n",
    "    print(f\"Datei gefunden: {excel_file}\")\n",
    "    df = pd.read_excel(excel_file)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    vorhandene_namen = {eintrag.get(\"transcription\") for eintrag in db}\n",
    "    neue_zaehler = 0  \n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        name = str(row.get(\"Name\", \"\")).strip()\n",
    "        \n",
    "        if name and name not in vorhandene_namen:\n",
    "            neu_eintrag = { \n",
    "                \"transcription\": name, \n",
    "                \"morphemes\": str(row.get(\"Morpheme\", \"\")).strip() if pd.notna(row.get(\"Morpheme\")) else \"\",\n",
    "                \"meaning\": str(row.get(\"Bedeutung\", \"\")).strip() if pd.notna(row.get(\"Bedeutung\")) else \"\",\n",
    "                \"position\": str(row.get(\"Position\", \"\")).strip() if pd.notna(row.get(\"Position\")) else \"\",\n",
    "                \"function\": str(row.get(\"Funktion\", \"\")).strip() if pd.notna(row.get(\"Funktion\")) else \"\"\n",
    "            }\n",
    "            db.append(neu_eintrag)\n",
    "            vorhandene_namen.add(name)\n",
    "            neue_zaehler += 1\n",
    "\n",
    "    print(f\"Import abgeschlossen: {neue_zaehler} Namen hinzugefuegt.\")\n",
    "    print(f\"Neuer Gesamtstand: {len(db)}\")\n",
    "else:\n",
    "    print(\"Keine Excel-Datei gefunden.\")\n",
    "\n",
    "\n",
    "with open(db_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(db, f, indent=4, ensure_ascii=False)\n",
    "print(f\"Daten erfolgreich in {db_file} gespeichert.\")\n",
    "\n",
    "\n",
    "def push_to_github():\n",
    "    os.system(\"git add .\")\n",
    "    commit_msg = \"Update database structure and entries\"\n",
    "    if os.system(f'git commit -m \"{commit_msg}\"') == 0:\n",
    "        os.system(\"git push origin main\")\n",
    "        print(\"GitHub Upload abgeschlossen.\")\n",
    "    else:\n",
    "        print(\"Keine neuen Änderungen für GitHub vorhanden.\")\n",
    "\n",
    "push_to_github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1080ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"kassite_names_db.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    \n",
    "    json.dump(db, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Die Datei 'kassite_names_db.json' wurde lokal aktualisiert!\")\n",
    "\n",
    "def push_to_github():\n",
    "    print(\" Starte GitHub-Upload...\")\n",
    "    os.system(\"git add .\")\n",
    "    \n",
    "    if os.system('git commit -m \"Integrated Excel data into JSON database\"') == 0:\n",
    "        os.system(\"git push origin main\")\n",
    "        print (\"Alles ist jetzt online auf GitHub!\")\n",
    "    else:\n",
    "        print(\"Keine neuen Änderungen zum Hochladen gefunden.\")\n",
    "\n",
    "push_to_github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def notebook_und_db_hochladen():\n",
    "    print(\"Starte Upload fuer Notebook und JSON...\")\n",
    "    \n",
    "    \n",
    "    os.system(\"git add .\")\n",
    "    \n",
    "    \n",
    "    commit_msg = \"Notebook und Datenbank aktualisiert\"\n",
    "    result = os.system(f'git commit -m \"{commit_msg}\"')\n",
    "    \n",
    "    \n",
    "    if result == 0:\n",
    "        os.system(\"git push origin main\")\n",
    "        print(\"Erfolg: Notebook und Datenbank sind jetzt auf GitHub aktuell!\")\n",
    "    else:\n",
    "        print(\"Info: Keine neuen Aenderungen im Notebook gefunden. Hast du gespeichert?\")\n",
    "\n",
    "\n",
    "notebook_und_db_hochladen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "db_file = \"kassite_names_db.json\"\n",
    "\n",
    "if os.path.exists(db_file):\n",
    "    with open(db_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        kassite_db = json.load(file)\n",
    "    print(f\"Database loaded! {len(kassite_db)} entries found.\")\n",
    "else:\n",
    "    kassite_db = []\n",
    "    print(\"New database initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lingpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792eda4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from lingpy import *\n",
    "\n",
    "db_file = \"kassite_names_db.json\"\n",
    "\n",
    "if os.path.exists(db_file):\n",
    "    with open(db_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        db = json.load(f)\n",
    "    print(f\"Datenbank geladen: {len(db)} Eintraege.\")\n",
    "lp_data = {}\n",
    "\n",
    "lp_data[0] = [\"doculect\",\"concept\",\"transcription\", \"morphemes\"]\n",
    "\n",
    "for i, eintrag in enumerate(db):\n",
    "    lp_data[i+1] = [ \n",
    "\"Kassitisch\",                  \n",
    "        eintrag.get(\"meaning\", \"NA\"),   \n",
    "        eintrag.get(\"transcription\", \"\"),\n",
    "        eintrag.get(\"morphemes\", \"\")     \n",
    "    ]\n",
    "columns = [\"transcription\"], \"meaning\", \"morphemes\"\n",
    "wl = Wordlist(lp_data, row='concept', col= 'doculect')\n",
    "\n",
    "print(f\"LingPy hat {wl.height} Einträge geladen.\")\n",
    "\n",
    "alle_morpheme = []\n",
    "for entry in db:\n",
    "    m = entry.get(\"morphemes\",\"\")\n",
    "    if m:\n",
    "        teile = [t.strip() for t in m.split(\"-\")]\n",
    "        alle_morpheme.extend(teile)\n",
    "        \n",
    "morphem_set = sorted(list(set(alle_morpheme)))  \n",
    "print(f\"Gefundene einzigartige Morpheme: {len(morphem_set)}\")      \n",
    "print(\"-\" * 30)   \n",
    "print(\"Vorschau der ersten 10 Morpheme:\")\n",
    "print(morphem_set[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c375c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from lingpy import *\n",
    "from lingpy.sequence.sound_classes import tokens2class\n",
    "\n",
    "\n",
    "db_file = \"kassite_names_db.json\"\n",
    "if not os.path.exists(db_file):\n",
    "    print(f\"Fehler: {db_file} nicht gefunden!\")\n",
    "else:\n",
    "    with open(db_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        db = json.load(f)\n",
    "\n",
    "\n",
    "    lp_data = {0: [\"doculect\", \"concept\", \"transcription\", \"morphemes\"]}\n",
    "    for i, entry in enumerate(db):\n",
    "        lp_data[i+1] = [\n",
    "            \"Kassitisch\",\n",
    "            entry.get(\"meaning\", \"NA\"),\n",
    "            entry.get(\"transcription\", \"\"),\n",
    "            entry.get(\"morphemes\", \"\")\n",
    "        ]\n",
    "\n",
    "    wl = Wordlist(lp_data)\n",
    "\n",
    "    wl.add_entries('tokens', 'transcription', lambda x: list(x.replace('-', '').lower()))\n",
    "\n",
    "\n",
    "    print(f\"{'Name':<15} | {'Vorschau Tokens':<20} | {'CV-Muster'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    indices = [i for i in lp_data.keys() if i != 0]\n",
    "    updated_db = []\n",
    "\n",
    "    for idx in indices:\n",
    "        name = wl[idx, 'transcription']\n",
    "        tokens = wl[idx, 'tokens']\n",
    "        \n",
    "        try:\n",
    "            cv_list = tokens2class(tokens, 'cv')\n",
    "            cv_pattern = \"\".join(cv_list)\n",
    "        except:\n",
    "            cv_pattern = \"NA\"\n",
    "\n",
    "        updated_db.append({\n",
    "            \"transcription\": name,\n",
    "            \"meaning\": wl[idx, 'concept'],\n",
    "            \"morphemes\": wl[idx, 'morphemes'],\n",
    "            \"tokens\": tokens,\n",
    "            \"structure\": cv_pattern\n",
    "        })\n",
    "\n",
    "\n",
    "        if idx <= 10:\n",
    "            token_str = str(tokens[:3]).replace('[', '').replace(']', '').replace(\"'\", \"\")\n",
    "            print(f\"{name:<15} | {token_str + '...':<20} | {cv_pattern}\")\n",
    "\n",
    "\n",
    "    output_file = \"kassite_names_db_analyzed.json\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(updated_db, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"\\n Analyse in {output_file} gespeichert.\")\n",
    "\n",
    "\n",
    "    print(\"⬆️ Starte GitHub Upload...\")\n",
    "    os.system(\"git add .\")\n",
    "    commit_msg = \"Automated LingPy analysis: tokens and CV-patterns\"\n",
    "    os.system(f'git commit -m \"{commit_msg}\"')\n",
    "    os.system(\"git push origin main\")\n",
    "    print(\" Alles sicher auf GitHub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1168a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a30510",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54dcd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
